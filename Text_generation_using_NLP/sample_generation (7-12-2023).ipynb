{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0d010821-beb0-4b98-86e4-a996a9299d69",
      "metadata": {
        "id": "0d010821-beb0-4b98-86e4-a996a9299d69"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from random import randint\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "158697fe-9b67-400c-ad89-8f4070aca3b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "158697fe-9b67-400c-ad89-8f4070aca3b5",
        "outputId": "ad7dd9b0-5f54-4c79-9be1-8a89adc64896"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8d5cc391-93bb-473a-a73c-8b84f4c41668",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "8d5cc391-93bb-473a-a73c-8b84f4c41668",
        "outputId": "7182e987-6bcc-4aad-ea26-6c7288b8c1f4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A Game Of Thrones \\nBook One of A Song of Ice and Fire \\nBy George R. R. Martin \\nPROLOGUE \\n\"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \\ndead.\" \\n\"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile. \\nGared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go. \\n\"Dead is dead,\" he said. \"We have no business with the dead.\" \\n\"Are they dead?\" Royce asked softly. \"What proof have we?\" \\n\"Will saw them,\" Gared said. \"If he says they are dead, that\\'s proof enough for me.\" \\nWill had known they would drag him into the quarrel sooner or later. He wished it had been later rather \\nthan sooner. \"My mother told me that dead men sing no songs,\" he put in. \\n\"My wet nurse said the same thing, Will,\" Royce replied. \"Never believe anything you hear at a woman\\'s \\ntit. There are things to be learned even from the dead.\" His voice echoed, too loud in the twilit forest. \\nPage 1\\n\\n\"We have a long ride before us,\" Gared pointed out. \"Eight days, maybe nine. And night is falling.\" \\nSer Waymar Royce glanced at the sky with disinterest. \"It does that every day about this time. Are you \\nunmanned by the dark, Gared?\" \\nWill could see the tightness around Gared\\'s mouth, the barely sup \\npressed anger in his eyes under the thick black hood of his cloak. Gared had spent forty years in the \\nNight\\'s Watch, man and boy, and he was not accustomed to being made light of. Yet it was more than \\nthat. Under the wounded pride, Will could sense something else in the older man. You could taste it; a \\nnervous tension that came perilous close to fear. \\nWill shared his unease. He had been four years on the Wall. The first time he had been sent beyond, all \\nthe old stories had come rushing back, and his bowels had turned to water. He had laughed about it \\nafterward. He was a veteran of a hundred rangings by now, and the endless dark wilderness that the \\nsouthron called the haunted forest had '"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = open('001ssb.txt', 'r')\n",
        "text = data.read()\n",
        "text[0:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "29dc1b8b-0754-4b12-8688-05f859fd0ef6",
      "metadata": {
        "id": "29dc1b8b-0754-4b12-8688-05f859fd0ef6"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "    #Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s\", ' ', sentence)\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    return sentence.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8f74acd3-6727-4496-98c1-1cc51cdbe7b5",
      "metadata": {
        "id": "8f74acd3-6727-4496-98c1-1cc51cdbe7b5"
      },
      "outputs": [],
      "source": [
        "text_processed = preprocess_text(text)\n",
        "text_processed = text_processed[0:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4b3f68f8-f497-4f55-a852-221695e05a9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b3f68f8-f497-4f55-a852-221695e05a9a",
        "outputId": "35d2d2d8-0134-4950-afec-e7ab5580ce32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words: 1915\n",
            "Unique words: 705\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text_words = (word_tokenize(text_processed))\n",
        "n_words = len(text_words)\n",
        "unique_words = len(set(text_words))\n",
        "\n",
        "print('Total words: %d' % n_words)\n",
        "print('Unique words: %d' % unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2c913ac5-85b3-409f-a430-e07e4ed36e07",
      "metadata": {
        "id": "2c913ac5-85b3-409f-a430-e07e4ed36e07"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=11318)\n",
        "tokenizer.fit_on_texts(text_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f1cad42f-d592-4615-a37d-a2c3abf0e469",
      "metadata": {
        "id": "f1cad42f-d592-4615-a37d-a2c3abf0e469"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "word_2_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0c04ff80-7831-4e1c-970b-b14cca2fbdbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c04ff80-7831-4e1c-970b-b14cca2fbdbd",
        "outputId": "d7b31dfd-c009-4320-af83-a4f43eb129ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "especially\n",
            "347\n"
          ]
        }
      ],
      "source": [
        "print(text_words[500])\n",
        "print(word_2_index[text_words[500]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "39fe65d6-4c92-438b-96ae-ed9132892e36",
      "metadata": {
        "id": "39fe65d6-4c92-438b-96ae-ed9132892e36"
      },
      "outputs": [],
      "source": [
        "input_sequence = []\n",
        "output_words = []\n",
        "input_seq_length = 100\n",
        "\n",
        "for i in range(0, n_words - input_seq_length, 1):\n",
        "    in_seq = text_words[i: i + input_seq_length]\n",
        "    out_seq = text_words[i + input_seq_length]\n",
        "    input_sequence.append([word_2_index[word] for word in in_seq])\n",
        "    output_words.append(word_2_index[out_seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f176f2cf-2176-4fa2-8a46-693c8e60c3a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f176f2cf-2176-4fa2-8a46-693c8e60c3a9",
        "outputId": "426c70ed-0bc8-4e5e-91f4-f2b9d0a163b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7, 28, 18, 37, 19, 258, 27, 1, 24, 44, 32, 24, 15, 51, 259, 66, 150, 37, 18, 8, 52, 40, 12, 28, 86, 7, 260, 32, 44, 24, 13, 150, 67, 20, 53, 8, 4, 261, 32, 112, 262, 33, 113, 1, 263, 151, 87, 152, 7, 264, 3, 4, 21, 152, 265, 54, 151, 55, 266, 153, 53, 13, 24, 46, 267, 19, 268, 7, 154, 14, 55, 269, 270, 28, 1, 155, 271, 8, 15, 272, 68, 273, 274, 10, 156, 22, 157, 275, 29, 44, 158, 6, 114, 276, 277, 47, 1, 24, 9, 278]\n"
          ]
        }
      ],
      "source": [
        "print(input_sequence[76])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a4273219-f1dc-484a-92fb-3072e50bbb82",
      "metadata": {
        "id": "a4273219-f1dc-484a-92fb-3072e50bbb82"
      },
      "outputs": [],
      "source": [
        "X = np.reshape(input_sequence, (len(input_sequence), input_seq_length, 1))\n",
        "X = X / float(vocab_size)\n",
        "\n",
        "y = to_categorical(output_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d16c857e-b734-4ff6-b6c7-e3c24925eb52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d16c857e-b734-4ff6-b6c7-e3c24925eb52",
        "outputId": "5ee41aa9-b4a1-4b0f-be52-d01a2fb50bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape:\t (1815, 100, 1)\n",
            "y shape:\t (1815, 706)\n"
          ]
        }
      ],
      "source": [
        "print(\"X shape:\\t\", X.shape)\n",
        "print(\"y shape:\\t\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "464c3745-14e3-49aa-881f-b71bd80b6854",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "464c3745-14e3-49aa-881f-b71bd80b6854",
        "outputId": "8c592489-177b-43b6-c4c0-3b9e49ac59ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0.34135977],\n",
              "        [0.3427762 ],\n",
              "        [0.00708215],\n",
              "        ...,\n",
              "        [0.05665722],\n",
              "        [0.01699717],\n",
              "        [0.03966006]],\n",
              "\n",
              "       [[0.3427762 ],\n",
              "        [0.00708215],\n",
              "        [0.34419263],\n",
              "        ...,\n",
              "        [0.01699717],\n",
              "        [0.03966006],\n",
              "        [0.12181303]],\n",
              "\n",
              "       [[0.00708215],\n",
              "        [0.34419263],\n",
              "        [0.34560907],\n",
              "        ...,\n",
              "        [0.03966006],\n",
              "        [0.12181303],\n",
              "        [0.00991501]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.25212465],\n",
              "        [0.01133144],\n",
              "        [0.05382436],\n",
              "        ...,\n",
              "        [0.00566572],\n",
              "        [0.18696884],\n",
              "        [0.02974504]],\n",
              "\n",
              "       [[0.01133144],\n",
              "        [0.05382436],\n",
              "        [0.19971671],\n",
              "        ...,\n",
              "        [0.18696884],\n",
              "        [0.02974504],\n",
              "        [0.99716714]],\n",
              "\n",
              "       [[0.05382436],\n",
              "        [0.19971671],\n",
              "        [0.00424929],\n",
              "        ...,\n",
              "        [0.02974504],\n",
              "        [0.99716714],\n",
              "        [0.01983003]]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "911ae932-90ea-4907-a4e6-b5b7571ed4ed",
      "metadata": {
        "id": "911ae932-90ea-4907-a4e6-b5b7571ed4ed"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "779985b3-4940-4007-a263-75188896da65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "779985b3-4940-4007-a263-75188896da65",
        "outputId": "3748ab7e-d208-479c-b64c-a6f9aae337f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 800)          2566400   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 600)          3362400   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 800)               4483200   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 706)               565506    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10977506 (41.88 MB)\n",
            "Trainable params: 10977506 (41.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(800, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(600, return_sequences=True))\n",
        "model.add(LSTM(800))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7db2a6d5-1b18-4507-99ec-278eb031ceb3",
      "metadata": {
        "id": "7db2a6d5-1b18-4507-99ec-278eb031ceb3"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Zo7yjcg6vLMA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo7yjcg6vLMA",
        "outputId": "be329116-aa82-4e7d-973b-e2a5951491b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.engine.sequential.Sequential at 0x7fccd41f67d0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9d4263b8-88d2-4333-a6ed-caa7cfd42c6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d4263b8-88d2-4333-a6ed-caa7cfd42c6f",
        "outputId": "305b517f-abe6-4234-b2c3-e65009b441e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 14s 142ms/step - loss: 6.2525\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 5.8902\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 5.8369\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 4s 142ms/step - loss: 5.8162\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 4s 144ms/step - loss: 5.8139\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 4s 144ms/step - loss: 5.8095\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 4s 144ms/step - loss: 5.8033\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 4s 146ms/step - loss: 5.8058\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 4s 147ms/step - loss: 5.8019\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 4s 151ms/step - loss: 5.7980\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 5.7973\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 4s 150ms/step - loss: 5.7956\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 4s 152ms/step - loss: 5.7982\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 5.7937\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 5.7924\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 5.7892\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7889\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7884\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7843\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 5s 161ms/step - loss: 5.7859\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 5s 162ms/step - loss: 5.7879\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 5s 160ms/step - loss: 5.7852\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 5s 160ms/step - loss: 5.7839\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7812\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7825\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7801\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 5.7806\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 5.7801\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 5.7797\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 5.7801\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 5.7797\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 5.7779\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 5.7769\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7760\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7790\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7791\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7743\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7781\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7761\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7754\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7758\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7752\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7754\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7747\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7748\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7762\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7741\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7753\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7735\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7733\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7723\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7734\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7782\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7748\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7718\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7716\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7735\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7722\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7721\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7723\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7711\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7710\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7691\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7718\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7701\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7725\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7710\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7695\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7692\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7696\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7703\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7706\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7698\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7689\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7685\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7721\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7699\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7692\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7678\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7694\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7692\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7688\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7684\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7683\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7681\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7676\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7670\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 5s 160ms/step - loss: 5.7672\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7667\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7675\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7672\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7680\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7662\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.7667\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 5.9249\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 5.7707\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 5.7692\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 5.7693\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 5.7700\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 5.7677\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fccc8c47f10>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X, y, batch_size=64, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "98e48f14-0c95-4778-8ea8-b897a4f818b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98e48f14-0c95-4778-8ea8-b897a4f818b6",
        "outputId": "58e8804e-27af-4ffe-a55e-d578d978739c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knight turned back to his grizzled man at arms frostfallen leaves whispered past them and royce destrier moved restlessly what do you think might have killed these men gared ser waymar asked casually he adjusted the drape of his long sable cloak it was the cold gared said with iron certainty saw men freeze last winter and the one before when was half boy everyone talks about snows forty foot deep and how the ice wind comes howling out of the north but the real enemy is the cold it steals up on you quieter than will and at first\n"
          ]
        }
      ],
      "source": [
        "random_seq_index = np.random.randint(0, len(input_sequence) - 1)\n",
        "random_seq = input_sequence[random_seq_index]\n",
        "\n",
        "index_2_word = dict(map(reversed, word_2_index.items()))\n",
        "\n",
        "word_sequence = [index_2_word[value] for value in random_seq]\n",
        "\n",
        "print(' '.join(word_sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9dbde4ea-ea1a-4216-8f8c-4e48e62a0120",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dbde4ea-ea1a-4216-8f8c-4e48e62a0120",
        "outputId": "d7a0c16d-7415-45c4-96a9-4fdb35542c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 907ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            " knight turned back to his grizzled man at arms frostfallen leaves whispered past them and royce destrier moved restlessly what do you think might have killed these men gared ser waymar asked casually he adjusted the drape of his long sable cloak it was the cold gared said with iron certainty saw men freeze last winter and the one before when was half boy everyone talks about snows forty foot deep and how the ice wind comes howling out of the north but the real enemy is the cold it steals up on you quieter than will and at first the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ]
        }
      ],
      "source": [
        "for i in range(100):\n",
        "  int_sample = np.reshape(random_seq, (1, len(random_seq), 1))\n",
        "  int_sample = int_sample / float(vocab_size)\n",
        "\n",
        "  predicted_word_index = model.predict(int_sample, verbose = 1)\n",
        "\n",
        "  predicted_word_id = np.argmax(predicted_word_index)\n",
        "  seq_in = [index_2_word[index] for index in random_seq]\n",
        "\n",
        "  word_sequence.append(index_2_word[predicted_word_id])\n",
        "\n",
        "  random_seq.append(predicted_word_id)\n",
        "  random_seq = random_seq[1: len(random_seq)]\n",
        "\n",
        "  final_output = \"\"\n",
        "  for word in word_sequence:\n",
        "    final_output = final_output + \" \" + word\n",
        "\n",
        "print(final_output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
